{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.transformation import YeoJohnsonTransformer\n",
    "from feature_engine.transformation import LogCpTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "       cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont5  \\\nid                                                        ...             \n1         A    B    A    A    B    D    A    E    C    I  ...  0.881122   \n2         B    A    A    A    B    B    A    E    A    F  ...  0.440011   \n3         A    A    A    C    B    D    A    B    C    N  ...  0.914155   \n4         A    A    A    C    B    D    A    E    G    K  ...  0.934138   \n6         A    B    A    A    B    B    A    E    C    F  ...  0.382600   \n...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n499993    A    B    A    C    B    B    A    E    E    L  ...  0.269578   \n499996    A    B    A    C    B    B    A    E    E    L  ...  0.197211   \n499997    A    B    A    C    B    B    A    E    C    M  ...  0.449482   \n499998    A    B    B    C    B    B    A    D    E    F  ...  0.363130   \n499999    A    A    B    A    B    D    A    E    C    K  ...  0.734712   \n\n           cont6     cont7     cont8     cont9    cont10    cont11    cont12  \\\nid                                                                             \n1       0.421650  0.741413  0.895799  0.802461  0.724417  0.701915  0.877618   \n2       0.346230  0.278495  0.593413  0.546056  0.613252  0.741289  0.326679   \n3       0.369602  0.832564  0.865620  0.825251  0.264104  0.695561  0.869133   \n4       0.578930  0.407313  0.868099  0.794402  0.494269  0.698125  0.809799   \n6       0.705940  0.325193  0.440967  0.462146  0.724447  0.683073  0.343457   \n...          ...       ...       ...       ...       ...       ...       ...   \n499993  0.258655  0.363598  0.300619  0.340516  0.235711  0.383477  0.215227   \n499996  0.257024  0.574304  0.227035  0.322583  0.286094  0.324874  0.306933   \n499997  0.386172  0.476217  0.135947  0.502730  0.235788  0.316671  0.250286   \n499998  0.324132  0.229017  0.220888  0.515304  0.389391  0.245234  0.303895   \n499999  0.404145  0.497719  0.497974  0.782585  0.751251  0.608412  0.712868   \n\n          cont13    target  \nid                          \n1       0.719903  6.994023  \n2       0.808464  8.071256  \n3       0.828352  5.760456  \n4       0.614766  7.806457  \n6       0.297743  6.868974  \n...          ...       ...  \n499993  0.793630  8.343538  \n499996  0.230902  7.851861  \n499997  0.349041  7.600558  \n499998  0.481138  8.272095  \n499999  0.452400  6.025685  \n\n[300000 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>cat9</th>\n      <th>...</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n      <th>target</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>I</td>\n      <td>...</td>\n      <td>0.881122</td>\n      <td>0.421650</td>\n      <td>0.741413</td>\n      <td>0.895799</td>\n      <td>0.802461</td>\n      <td>0.724417</td>\n      <td>0.701915</td>\n      <td>0.877618</td>\n      <td>0.719903</td>\n      <td>6.994023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>F</td>\n      <td>...</td>\n      <td>0.440011</td>\n      <td>0.346230</td>\n      <td>0.278495</td>\n      <td>0.593413</td>\n      <td>0.546056</td>\n      <td>0.613252</td>\n      <td>0.741289</td>\n      <td>0.326679</td>\n      <td>0.808464</td>\n      <td>8.071256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>B</td>\n      <td>C</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0.914155</td>\n      <td>0.369602</td>\n      <td>0.832564</td>\n      <td>0.865620</td>\n      <td>0.825251</td>\n      <td>0.264104</td>\n      <td>0.695561</td>\n      <td>0.869133</td>\n      <td>0.828352</td>\n      <td>5.760456</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>G</td>\n      <td>K</td>\n      <td>...</td>\n      <td>0.934138</td>\n      <td>0.578930</td>\n      <td>0.407313</td>\n      <td>0.868099</td>\n      <td>0.794402</td>\n      <td>0.494269</td>\n      <td>0.698125</td>\n      <td>0.809799</td>\n      <td>0.614766</td>\n      <td>7.806457</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>F</td>\n      <td>...</td>\n      <td>0.382600</td>\n      <td>0.705940</td>\n      <td>0.325193</td>\n      <td>0.440967</td>\n      <td>0.462146</td>\n      <td>0.724447</td>\n      <td>0.683073</td>\n      <td>0.343457</td>\n      <td>0.297743</td>\n      <td>6.868974</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499993</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0.269578</td>\n      <td>0.258655</td>\n      <td>0.363598</td>\n      <td>0.300619</td>\n      <td>0.340516</td>\n      <td>0.235711</td>\n      <td>0.383477</td>\n      <td>0.215227</td>\n      <td>0.793630</td>\n      <td>8.343538</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0.197211</td>\n      <td>0.257024</td>\n      <td>0.574304</td>\n      <td>0.227035</td>\n      <td>0.322583</td>\n      <td>0.286094</td>\n      <td>0.324874</td>\n      <td>0.306933</td>\n      <td>0.230902</td>\n      <td>7.851861</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>M</td>\n      <td>...</td>\n      <td>0.449482</td>\n      <td>0.386172</td>\n      <td>0.476217</td>\n      <td>0.135947</td>\n      <td>0.502730</td>\n      <td>0.235788</td>\n      <td>0.316671</td>\n      <td>0.250286</td>\n      <td>0.349041</td>\n      <td>7.600558</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>D</td>\n      <td>E</td>\n      <td>F</td>\n      <td>...</td>\n      <td>0.363130</td>\n      <td>0.324132</td>\n      <td>0.229017</td>\n      <td>0.220888</td>\n      <td>0.515304</td>\n      <td>0.389391</td>\n      <td>0.245234</td>\n      <td>0.303895</td>\n      <td>0.481138</td>\n      <td>8.272095</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>K</td>\n      <td>...</td>\n      <td>0.734712</td>\n      <td>0.404145</td>\n      <td>0.497719</td>\n      <td>0.497974</td>\n      <td>0.782585</td>\n      <td>0.751251</td>\n      <td>0.608412</td>\n      <td>0.712868</td>\n      <td>0.452400</td>\n      <td>6.025685</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_data = pd.read_csv('../data/train.csv', index_col='id')\n",
    "tb_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "range_scale = MinMaxScaler()\n",
    "X = tb_data.loc[:, :'cont13']\n",
    "Y = tb_data['target']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "       cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont4  \\\nid                                                        ...             \n1         A    B    A    A    B    D    A    E    C    I  ...  0.114564   \n2         B    A    A    A    B    B    A    E    A    F  ...  0.115723   \n3         A    A    A    C    B    D    A    B    C    N  ...  0.129890   \n4         A    A    A    C    B    D    A    E    G    K  ...  0.721352   \n6         A    B    A    A    B    B    A    E    C    F  ...  0.111686   \n...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n499993    A    B    A    C    B    B    A    E    E    L  ...  0.719690   \n499996    A    B    A    C    B    B    A    E    E    L  ...  0.729014   \n499997    A    B    A    C    B    B    A    E    C    M  ...  0.134425   \n499998    A    B    B    C    B    B    A    D    E    F  ...  0.707507   \n499999    A    A    B    A    B    D    A    E    C    K  ...  0.629733   \n\n           cont5     cont6     cont7     cont8     cont9    cont10    cont11  \\\nid                                                                             \n1       0.855691  0.359931  0.643496  0.882829  0.811322  0.685241  0.654854   \n2       0.465907  0.288058  0.084307  0.583471  0.526128  0.570654  0.695283   \n3       0.884880  0.310331  0.753604  0.852951  0.836672  0.210755  0.648330   \n4       0.902538  0.509813  0.239914  0.855406  0.802359  0.448007  0.650962   \n6       0.415176  0.630849  0.140716  0.432551  0.432796  0.685273  0.635506   \n...          ...       ...       ...       ...       ...       ...       ...   \n499993  0.315305  0.204602  0.187108  0.293608  0.297509  0.181488  0.327877   \n499996  0.251359  0.203048  0.441633  0.220760  0.277562  0.233423  0.267703   \n499997  0.474276  0.326122  0.323148  0.130585  0.477937  0.181568  0.259280   \n499998  0.397972  0.267000  0.024539  0.214676  0.491923  0.339900  0.185928   \n499999  0.726317  0.343249  0.349122  0.488986  0.789216  0.712902  0.558844   \n\n          cont12    cont13  \nid                          \n1       0.913387  0.785206  \n2       0.343629  0.908989  \n3       0.904611  0.936786  \n4       0.843251  0.638256  \n6       0.360980  0.195151  \n...          ...       ...  \n499993  0.228370  0.888255  \n499996  0.323208  0.101727  \n499997  0.264627  0.266850  \n499998  0.320067  0.451483  \n499999  0.743009  0.411316  \n\n[300000 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat0</th>\n      <th>cat1</th>\n      <th>cat2</th>\n      <th>cat3</th>\n      <th>cat4</th>\n      <th>cat5</th>\n      <th>cat6</th>\n      <th>cat7</th>\n      <th>cat8</th>\n      <th>cat9</th>\n      <th>...</th>\n      <th>cont4</th>\n      <th>cont5</th>\n      <th>cont6</th>\n      <th>cont7</th>\n      <th>cont8</th>\n      <th>cont9</th>\n      <th>cont10</th>\n      <th>cont11</th>\n      <th>cont12</th>\n      <th>cont13</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>I</td>\n      <td>...</td>\n      <td>0.114564</td>\n      <td>0.855691</td>\n      <td>0.359931</td>\n      <td>0.643496</td>\n      <td>0.882829</td>\n      <td>0.811322</td>\n      <td>0.685241</td>\n      <td>0.654854</td>\n      <td>0.913387</td>\n      <td>0.785206</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>A</td>\n      <td>F</td>\n      <td>...</td>\n      <td>0.115723</td>\n      <td>0.465907</td>\n      <td>0.288058</td>\n      <td>0.084307</td>\n      <td>0.583471</td>\n      <td>0.526128</td>\n      <td>0.570654</td>\n      <td>0.695283</td>\n      <td>0.343629</td>\n      <td>0.908989</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>B</td>\n      <td>C</td>\n      <td>N</td>\n      <td>...</td>\n      <td>0.129890</td>\n      <td>0.884880</td>\n      <td>0.310331</td>\n      <td>0.753604</td>\n      <td>0.852951</td>\n      <td>0.836672</td>\n      <td>0.210755</td>\n      <td>0.648330</td>\n      <td>0.904611</td>\n      <td>0.936786</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A</td>\n      <td>A</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>G</td>\n      <td>K</td>\n      <td>...</td>\n      <td>0.721352</td>\n      <td>0.902538</td>\n      <td>0.509813</td>\n      <td>0.239914</td>\n      <td>0.855406</td>\n      <td>0.802359</td>\n      <td>0.448007</td>\n      <td>0.650962</td>\n      <td>0.843251</td>\n      <td>0.638256</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>F</td>\n      <td>...</td>\n      <td>0.111686</td>\n      <td>0.415176</td>\n      <td>0.630849</td>\n      <td>0.140716</td>\n      <td>0.432551</td>\n      <td>0.432796</td>\n      <td>0.685273</td>\n      <td>0.635506</td>\n      <td>0.360980</td>\n      <td>0.195151</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>499993</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0.719690</td>\n      <td>0.315305</td>\n      <td>0.204602</td>\n      <td>0.187108</td>\n      <td>0.293608</td>\n      <td>0.297509</td>\n      <td>0.181488</td>\n      <td>0.327877</td>\n      <td>0.228370</td>\n      <td>0.888255</td>\n    </tr>\n    <tr>\n      <th>499996</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>E</td>\n      <td>L</td>\n      <td>...</td>\n      <td>0.729014</td>\n      <td>0.251359</td>\n      <td>0.203048</td>\n      <td>0.441633</td>\n      <td>0.220760</td>\n      <td>0.277562</td>\n      <td>0.233423</td>\n      <td>0.267703</td>\n      <td>0.323208</td>\n      <td>0.101727</td>\n    </tr>\n    <tr>\n      <th>499997</th>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>M</td>\n      <td>...</td>\n      <td>0.134425</td>\n      <td>0.474276</td>\n      <td>0.326122</td>\n      <td>0.323148</td>\n      <td>0.130585</td>\n      <td>0.477937</td>\n      <td>0.181568</td>\n      <td>0.259280</td>\n      <td>0.264627</td>\n      <td>0.266850</td>\n    </tr>\n    <tr>\n      <th>499998</th>\n      <td>A</td>\n      <td>B</td>\n      <td>B</td>\n      <td>C</td>\n      <td>B</td>\n      <td>B</td>\n      <td>A</td>\n      <td>D</td>\n      <td>E</td>\n      <td>F</td>\n      <td>...</td>\n      <td>0.707507</td>\n      <td>0.397972</td>\n      <td>0.267000</td>\n      <td>0.024539</td>\n      <td>0.214676</td>\n      <td>0.491923</td>\n      <td>0.339900</td>\n      <td>0.185928</td>\n      <td>0.320067</td>\n      <td>0.451483</td>\n    </tr>\n    <tr>\n      <th>499999</th>\n      <td>A</td>\n      <td>A</td>\n      <td>B</td>\n      <td>A</td>\n      <td>B</td>\n      <td>D</td>\n      <td>A</td>\n      <td>E</td>\n      <td>C</td>\n      <td>K</td>\n      <td>...</td>\n      <td>0.629733</td>\n      <td>0.726317</td>\n      <td>0.343249</td>\n      <td>0.349122</td>\n      <td>0.488986</td>\n      <td>0.789216</td>\n      <td>0.712902</td>\n      <td>0.558844</td>\n      <td>0.743009</td>\n      <td>0.411316</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_columns = X.select_dtypes(include=object).columns.to_list()\n",
    "cont_columns = X.select_dtypes(include=np.number).columns.to_list()\n",
    "X[cont_columns] = range_scale.fit_transform(X[cont_columns])\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('rare', RareLabelEncoder(n_categories=3,\n                    variables=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5',\n                               'cat6', 'cat7', 'cat8', 'cat9'])),\n  ('frequancy',\n   CountFrequencyEncoder(encoding_method='frequency',\n                         variables=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5',\n                                    'cat6', 'cat7', 'cat8', 'cat9'])),\n  ('winsorizer',\n   Winsorizer(capping_method='iqr', tail='both',\n              variables=['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n                         'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11',\n                         'cont12', 'cont13'])),\n  ('logit',\n   LogCpTransformer(C=0.001,\n                    variables=['cont3', 'cont4', 'cont5', 'cont7', 'cont11',\n                               'cont12', 'cont13'])),\n  ('yeo_johnson',\n   YeoJohnsonTransformer(variables=['cont0', 'cont1', 'cont2', 'cont6', 'cont8',\n                                    'cont9', 'cont10'])),\n  ('feature_selection',\n   SelectKBest(k=12,\n               score_func=<function mutual_info_regression at 0x0000027DC007BB80>))],\n 'verbose': False,\n 'rare': RareLabelEncoder(n_categories=3,\n                  variables=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5',\n                             'cat6', 'cat7', 'cat8', 'cat9']),\n 'frequancy': CountFrequencyEncoder(encoding_method='frequency',\n                       variables=['cat0', 'cat1', 'cat2', 'cat3', 'cat4', 'cat5',\n                                  'cat6', 'cat7', 'cat8', 'cat9']),\n 'winsorizer': Winsorizer(capping_method='iqr', tail='both',\n            variables=['cont0', 'cont1', 'cont2', 'cont3', 'cont4', 'cont5',\n                       'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11',\n                       'cont12', 'cont13']),\n 'logit': LogCpTransformer(C=0.001,\n                  variables=['cont3', 'cont4', 'cont5', 'cont7', 'cont11',\n                             'cont12', 'cont13']),\n 'yeo_johnson': YeoJohnsonTransformer(variables=['cont0', 'cont1', 'cont2', 'cont6', 'cont8',\n                                  'cont9', 'cont10']),\n 'feature_selection': SelectKBest(k=12,\n             score_func=<function mutual_info_regression at 0x0000027DC007BB80>),\n 'rare__ignore_format': False,\n 'rare__max_n_categories': None,\n 'rare__n_categories': 3,\n 'rare__replace_with': 'Rare',\n 'rare__tol': 0.05,\n 'rare__variables': ['cat0',\n  'cat1',\n  'cat2',\n  'cat3',\n  'cat4',\n  'cat5',\n  'cat6',\n  'cat7',\n  'cat8',\n  'cat9'],\n 'frequancy__encoding_method': 'frequency',\n 'frequancy__ignore_format': False,\n 'frequancy__variables': ['cat0',\n  'cat1',\n  'cat2',\n  'cat3',\n  'cat4',\n  'cat5',\n  'cat6',\n  'cat7',\n  'cat8',\n  'cat9'],\n 'winsorizer__capping_method': 'iqr',\n 'winsorizer__fold': 3,\n 'winsorizer__missing_values': 'raise',\n 'winsorizer__tail': 'both',\n 'winsorizer__variables': ['cont0',\n  'cont1',\n  'cont2',\n  'cont3',\n  'cont4',\n  'cont5',\n  'cont6',\n  'cont7',\n  'cont8',\n  'cont9',\n  'cont10',\n  'cont11',\n  'cont12',\n  'cont13'],\n 'logit__C': 0.001,\n 'logit__base': 'e',\n 'logit__variables': ['cont3',\n  'cont4',\n  'cont5',\n  'cont7',\n  'cont11',\n  'cont12',\n  'cont13'],\n 'yeo_johnson__variables': ['cont0',\n  'cont1',\n  'cont2',\n  'cont6',\n  'cont8',\n  'cont9',\n  'cont10'],\n 'feature_selection__k': 12,\n 'feature_selection__score_func': <function sklearn.feature_selection._mutual_info.mutual_info_regression(X, y, *, discrete_features='auto', n_neighbors=3, copy=True, random_state=None)>}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_line = Pipeline(steps=[('rare', RareLabelEncoder(n_categories=3,\n",
    "                                                      variables=cat_columns)),\n",
    "                            ('frequancy', CountFrequencyEncoder(encoding_method='frequency',\n",
    "                                                                variables=cat_columns)),\n",
    "                            ('winsorizer', Winsorizer(capping_method='iqr', tail='both',\n",
    "                                                      variables=cont_columns)),\n",
    "                            ('logit', LogCpTransformer(C=0.001, variables=['cont3', 'cont4', 'cont5', 'cont7',\n",
    "                                                                           'cont11', 'cont12', 'cont13'])),\n",
    "                            ('yeo_johnson', YeoJohnsonTransformer(variables=['cont0', 'cont1', 'cont2', 'cont6',\n",
    "                                                                             'cont8', 'cont9', 'cont10'\n",
    "                                                                             ])),\n",
    "                            ('feature_selection', SelectKBest(score_func=mutual_info_regression, k=12))\n",
    "                            ])\n",
    "base_line.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hewar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:179: UserWarning: The number of unique categories for variable cat0 is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\hewar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:179: UserWarning: The number of unique categories for variable cat1 is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\hewar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:179: UserWarning: The number of unique categories for variable cat2 is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_ = base_line.fit_transform(X, Y)\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_, Y, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=8, n_repeats=16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- linear models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'memory': None,\n 'steps': [('poly', PolynomialFeatures()), ('elasticNet', ElasticNet())],\n 'verbose': False,\n 'poly': PolynomialFeatures(),\n 'elasticNet': ElasticNet(),\n 'poly__degree': 2,\n 'poly__include_bias': True,\n 'poly__interaction_only': False,\n 'poly__order': 'C',\n 'elasticNet__alpha': 1.0,\n 'elasticNet__copy_X': True,\n 'elasticNet__fit_intercept': True,\n 'elasticNet__l1_ratio': 0.5,\n 'elasticNet__max_iter': 1000,\n 'elasticNet__normalize': 'deprecated',\n 'elasticNet__positive': False,\n 'elasticNet__precompute': False,\n 'elasticNet__random_state': None,\n 'elasticNet__selection': 'cyclic',\n 'elasticNet__tol': 0.0001,\n 'elasticNet__warm_start': False}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_net = Pipeline(steps=[('poly', PolynomialFeatures()),\n",
    "                              ('elasticNet', ElasticNet())])\n",
    "elastic_net.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'cv': RepeatedKFold(n_repeats=16, n_splits=8, random_state=None),\n 'error_score': nan,\n 'estimator__memory': None,\n 'estimator__steps': [('poly', PolynomialFeatures()),\n  ('elasticNet', ElasticNet())],\n 'estimator__verbose': False,\n 'estimator__poly': PolynomialFeatures(),\n 'estimator__elasticNet': ElasticNet(),\n 'estimator__poly__degree': 2,\n 'estimator__poly__include_bias': True,\n 'estimator__poly__interaction_only': False,\n 'estimator__poly__order': 'C',\n 'estimator__elasticNet__alpha': 1.0,\n 'estimator__elasticNet__copy_X': True,\n 'estimator__elasticNet__fit_intercept': True,\n 'estimator__elasticNet__l1_ratio': 0.5,\n 'estimator__elasticNet__max_iter': 1000,\n 'estimator__elasticNet__normalize': 'deprecated',\n 'estimator__elasticNet__positive': False,\n 'estimator__elasticNet__precompute': False,\n 'estimator__elasticNet__random_state': None,\n 'estimator__elasticNet__selection': 'cyclic',\n 'estimator__elasticNet__tol': 0.0001,\n 'estimator__elasticNet__warm_start': False,\n 'estimator': Pipeline(steps=[('poly', PolynomialFeatures()), ('elasticNet', ElasticNet())]),\n 'n_iter': 16,\n 'n_jobs': -1,\n 'param_distributions': {'poly__degree': [2, 3],\n  'elasticNet__alpha': [0.0001, 0.01, 0.1, 0.5, 1, 10],\n  'elasticNet__l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n  'elasticNet__max_iter': [10000, 10000, 1000]},\n 'pre_dispatch': '2*n_jobs',\n 'random_state': None,\n 'refit': 'r2',\n 'return_train_score': True,\n 'scoring': [('r2', make_scorer(r2_score)),\n  ('mse', make_scorer(mean_squared_error, greater_is_better=False))],\n 'verbose': 0}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_iter = 16\n",
    "\n",
    "rgs = RandomizedSearchCV(estimator=elastic_net,\n",
    "                         param_distributions={'poly__degree': [2, 3],\n",
    "                                              'elasticNet__alpha': [0.0001, 0.01, 0.1, 0.5, 1, 10],\n",
    "                                              'elasticNet__l1_ratio': [0, 0.25, 0.5, 0.75, 1],\n",
    "                                              'elasticNet__max_iter': [10000, 10000, 1000]\n",
    "                                              },\n",
    "                         n_iter=max_iter,\n",
    "                         cv=cv,\n",
    "                         return_train_score=True,\n",
    "                         scoring=[('r2', make_scorer(r2_score)),\n",
    "                                  ('mse', make_scorer(mean_squared_error, greater_is_better=False))],\n",
    "                         refit='r2',\n",
    "                         n_jobs=-1)\n",
    "rgs.get_params()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rgs.fit(train_x, train_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}